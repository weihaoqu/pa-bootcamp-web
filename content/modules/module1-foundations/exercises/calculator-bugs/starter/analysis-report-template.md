# Analysis Report: Calculator Bugs

## Student Name: ___________________
## Date: ___________________

---

## Part 1: Static Analysis Findings (ESLint)

Run `npx eslint calculator.js` and record all findings below.

| # | Line | Rule | Description | Severity |
|---|------|------|-------------|----------|
| 1 |      |      |             |          |
| 2 |      |      |             |          |
| 3 |      |      |             |          |
| 4 |      |      |             |          |
| 5 |      |      |             |          |

**Total static analysis issues found:** ___

---

## Part 2: Dynamic Analysis Findings (Test Suite)

Run `node test-calculator.js` and record all test failures below.

| # | Test Name | Error Message | Root Cause |
|---|-----------|---------------|------------|
| 1 |           |               |            |
| 2 |           |               |            |
| 3 |           |               |            |
| 4 |           |               |            |
| 5 |           |               |            |

**Total dynamic analysis issues found:** ___

---

## Part 3: Comparison

### Which bugs did ONLY static analysis catch?
<!-- List bugs found by ESLint but NOT by running tests -->

1.
2.

### Which bugs did ONLY dynamic analysis catch?
<!-- List bugs found by tests but NOT by ESLint -->

1.
2.

### Which bugs were found by BOTH approaches?
<!-- List bugs caught by both ESLint and test failures -->

1.

---

## Part 4: Reflection

### Why can't static analysis catch all bugs?
<!-- Your answer (2-3 sentences) -->


### Why can't dynamic analysis catch all bugs?
<!-- Your answer (2-3 sentences) -->


### When would you prioritize one approach over the other?
<!-- Your answer (2-3 sentences) -->

